---
layout: archive
title: "My Statement of Purpose"
permalink: /sop/
author_profile: true
redirect_from:
  - /sop
  - /wenshu
---

Much as in human life, a robot’s success hinges on a careful orchestration of perception & control, intelligent planning making, and the ability to optimize its actions at every stage. Similarly, our own pathways require countless actions that are forks in the road with an impact on our feelings, time, results, and future. I gained this perspective while conceptualizing my first robot. Since then, I have been continuously pondered what it would take to create a truly intelligent, human-like agent. This question has nurtured my passion in the design robotic algorithms, not only because of the unmatched satisfaction I got from solving intricate problems in this field but also because I understood the value of research in driving innovation.

![image](https://github.com/user-attachments/assets/3367f37c-b3c6-46f1-919f-9854a97f9e75)


Despite as the [best overall performance undergraduate student](https://tianyi20.github.io/assets/Best_performance_Overall.pdf) that ranking first place along four years in my cohort, I consistently reminded myself that "Learning from books alone is always shallow; to truly understand, one must put it into practice". Driven by this belief, I worked as a research assistant under XJTLU’s Dr. Quan Zhang focusing on “Motion Planning” throughout my undergraduate life. Specifically, We developed to a novel motion planning method within digital twin system, leading to paper: “[Development of a Simple and Novel Digital Twin Framework for Industrial Robots in Intelligent Robotics Manufacturing](https://arxiv.org/pdf/2410.14934)[1], [Video](https://www.youtube.com/watch?v=f_BEMbMvFso&t=1s) (CASE 2024)”. The innovation of this work addressed the “delay” problem typically encountered in teleoperation motion planning by achieving a novel 58.82 Hz control & monitoring frequency. Our frameworks aimed to facilitate smooth teleoperation and feed relatively asymptotic trajectory into imitation learning tasks. However, I observed that traditional robotic systems struggled to handle flexible materials, particularly when dealing with deformable objects. To address this, I equipped the robot with a soft pneumatic gripper and developed a vision-calibrated motion planning framework, resulting in the publication: “[A Novel Approach to Grasping Control of Soft Robotic Grippers based on Digital Twin](https://arxiv.org/pdf/2410.14928)[2] (ICAC 2024)”. 

My curiosity about robot perception deepened further when I joined Yale University, inspired by the groundbreaking research of [Prof. Brian Scassellati](http://cs-www.cs.yale.edu/homes/scaz/) and (Prof. Aaron Dollar)[https://seas.yale.edu/faculty-research/faculty-directory/aaron-m-dollar]. I realized that robots still struggle with a seemingly fundamental problem - “Perception”. To the best of author’s knowledge, most contemporary robotics research heavily relies on assumptions about known dimensions, appearances, and materials of target objects, often requiring precise pre-defined CAD models, as seen in [Boston Dynamics' Atlas robot](https://bostondynamics.com/video/atlas-goes-hands-on/) [3]. In contrast, humans can effortlessly perceive any unseen objects’ physical properties like pose, appearance, and even mass of inertia. Motivated by this realization, fortunately, I took Prof. Scassellati’s course and embarked on solving a classical robotic challenge: liquid manipulation. The most challenging part is how to generate a feasible pouring trajectory given diverse poses and dimensions of different cups and bottles. To address this, I developed a category-level object pose and dimension estimation detector and formulated the trajectory planning problem as an optimization problem solved by scipy. [[Video](https://www.youtube.com/watch?v=oPvfIooH5HU); [detector github](https://github.com/Tianyi20/category-level-estimation-ROS-noetic) , [optimizer and moveit github](https://github.com/Tianyi20/liquid_manipulation_moveit)].. Despite these efforts, I found that the perception still limits at pre-trained category-level weights. Followed this thought, I fortunately worked with [Dr. Yifan Zhu](https://yifanzhu95.github.io/) in Prof. Dollar’s Group. We proposed an end-to-end framework to jointly optimize shape, appearance, and physical properties of the scene. This framework leverages a novel differentiable point-based object representation couped with a grid-based appearance field, which allows differentiable object collision detection and rendering. Given 3D cloud data and tactile sensor, the robot can eventually try to optimize objects’ appearance, geometry, and physical parameters. Although the optimization run is completed in under 15 mins, it still give a insight on a general solution for perception and runtime can be reduced by better initial guess and pre-trained models. This also leads paper: “[Real-to-Sim via End-to-End Differentiable Simulation and Rendering](https://arxiv.org/pdf/2412.00259)[4]”, Robotics and Automation Letters (RAL).

Although perception and motion planning are most fundamental components of robotics, achieving a truly intelligent robot requires much more efforts. For example, an intelligent agent should be capable of making strategic decisions in complex, sequential, task planning in the loop. More importantly, a "central brain" is needed to integrate the results from perception, task planning, and motion planning, enabling seamless decision-making across various scenarios. In addition, basic dynamics still have unresolved contact rich manipulation compared with traditional collision-free motion planning, like motion-in-cage with a underactuated dexterous hand. In summary, the goal for my Ph.D. is to have further insight of these components and hopefully give critical contributions to the academic society. 


[1] T. Xiang, B. Li, X. Pan and Q. Zhang, "Development of a Simple and Novel Digital Twin Framework for Industrial Robots in Intelligent Robotics Manufacturing," 2024 IEEE 20th International Conference on Automation Science and Engineering (CASE). Available: https://ieeexplore.ieee.org/abstract/document/10711459
[2] T. Xiang, B. Li, Q. Zhang, M. Leach and E. Lim, "A Novel Approach to Grasping Control of Soft Robotic Grippers based on Digital Twin," 2024 29th International Conference on Automation and Computing (ICAC). Available: https://ieeexplore.ieee.org/abstract/document/10718822
[3]“Atlas Goes Hands On,” Boston Dynamics. Accessed: Nov. 29, 2024. [Online]. Available: https://bostondynamics.com/video/atlas-goes-hands-on/
[4] Y. Zhu, T. Xiang, A. Dollar, and Z. Pan, “Real-to-Sim via End-to-End Differentiable Simulation and Rendering”. Robotics and Automation Letters (RAL), Manuscript submitted for publication. Available: https://arxiv.org/pdf/2412.00259


