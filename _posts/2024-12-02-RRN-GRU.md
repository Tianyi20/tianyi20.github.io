---
title: 'ROS launch file writing tutorial'
date: 2024-12-2
permalink: /posts/2024/12/RNN-GRU/
tags:
  - RNN-GRU

---
![image](https://github.com/user-attachments/assets/07c61aa0-d203-4a7e-af6e-cafc0446e094)

RNN用于处理序列数据。在传统的神经网络模型中，是从输入层到隐含层再到输出层，层与层之间是全连接的，每层之间的节点是无连接的。但是这种普通的神经网络对于很多问题却无能无力。例如，你要预测句子的下一个单词是什么，一般需要用到前面的单词，因为一个句子中前后单词并不是独立的。RNN之所以称为循环神经网路，即一个序列当前的输出与前面的输出也有关。具体的表现形式为网络会对前面的信息进行记忆并应用于当前输出的计算中，即隐藏层之间的节点不再无连接而是有连接的，并且隐藏层的输入不仅包括输入层的输出还包括上一时刻隐藏层的输出。理论上，RNN能够对任何长度的序列数据进行处理。但是在实践中，为了降低复杂性往往假设当前的状态只与前面的几个状态相关。

**RNN重要特点：每一步的参数共享**


首先给出RNN数学模型

![image](https://github.com/user-attachments/assets/7da9b351-9a3b-43e1-a199-bef079adc90a)

这也是最重要的，每一个当前层的参数和上一个层的参数有关，这就实现了实现当前输入结果与之前的计算挂钩的目的。

这里分开来看就是这样的
![image](https://github.com/user-attachments/assets/c66595d3-7012-4964-addf-5b3b8035ee15)

![image](https://github.com/user-attachments/assets/450f1fed-4a3a-42de-bf70-cc5332398982)


## GRU 引入了门机制
